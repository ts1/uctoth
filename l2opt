#!/usr/bin/env coffee

fs = require 'fs'
{ N_PHASES } = require './pattern'
minibatch = require './minibatch.coffee'
coeffs_to_weights = require './coeffs_to_weights.coffee'
match = require './match.coffee'
{ watch_file } = require './util'

argv = require 'yargs'
  .options
    min:
      desc: 'Minimum value to search'
      default: 0.001
      type: 'number'
      requiresArg: true
    max:
      desc: 'Maximum value to search'
      default: 10
      type: 'number'
      requiresArg: true
    p:
      alias: 'precision'
      desc: 'Search precision'
      default: 0.1
      type: 'number'
      requiresArg: true
    b:
      alias: 'book'
      desc: 'Database file'
      default: 'book.db'
      requiresArg: true
    l:
      alias: 'logistic'
      desc: 'Logistic regression'
      type: 'boolean'
    e:
      alias: 'epochs'
      desc: 'Train epochs'
      type: 'number'
      default: minibatch.defaults.epochs
    loop:
      desc: 'Loop forever'
      type: 'boolean'
    prefix:
      desc: 'Prefix of coeffs'
      default: 'tmp/l2opt/coeffs'
    weights:
      desc: 'Temporary weights file'
      default: 'tmp/l2opt/weights.json'
      requiresArg: true
    default_l2:
      desc: 'Default L2 value'
      default: minibatch.defaults.l2
      requiresArg: true
    s:
      alias: 'search'
      desc: 'Number of UCT search of match'
      default: match.defaults.search
    w:
      alias: 'wld'
      desc: 'WLD search depth'
      default: match.defaults.wld
    f:
      alias: 'full'
      desc: 'Full search depth'
      default: match.defaults.full
    phase:
      desc: 'Phase to optimize (default all)'
      type: 'number'
      requiresArg: true
    skip_cv:
      desc: 'Skip CV and use existing L2/* for starter'
      type: 'boolean'
    match_range:
      desc: 'Match-search range'
      default: 2
      requiresArg: true
    h:
      alias: 'help'
  .strict()
  .version false
  .argv

prepare_coeffs = (phase) ->
  orig_file = "tmp/coeffs#{phase}"
  if fs.existsSync(orig_file)
    fs.copyFileSync orig_file, "#{argv.prefix}#{phase}"
  else
    l2file = "L2/#{phase}"
    l2 =
      if fs.existsSync(l2file)
        parseFloat(fs.readFileSync(l2file))
      else
        argv.default_l2

    process.stdout.write "Preparing coeffs for phase #{phase} l2=#{l2}: "

    minibatch
      l2: l2
      book: argv.book
      phase: phase
      logistic: argv.logistic
      epochs: argv.epochs
      outfile: "#{argv.prefix}#{phase}"
      verbose: false

    process.stdout.write "done\n"

prepare = (phase) ->
  for p in [0...N_PHASES]
    if p != phase
      prepare_coeffs p unless fs.existsSync("#{argv.prefix}#{p}")

optimize_cv = (phase) ->
  if argv.skip_cv
    throw new Error "L2/#{phase} not found" unless fs.existsSync("L2/#{phase}")
    return

  samples = minibatch.load_samples
    book: argv.book
    phase: phase
    logistic: argv.logistic
    verbose: true
  l2 = minibatch
    search: true
    search_precision: 1 + argv.precision
    search_min: argv.min
    search_max: argv.max
    samples: samples
    phase: phase
    logistic: argv.logistic
    epochs: argv.epochs
  fs.writeFileSync "L2/#{phase}", "#{l2}\n"

try_value = (phase, value, max, samples) ->
  process.stdout.write "L2 #{value}: "

  coeffs = minibatch
    l2: value
    samples: samples
    phase: phase
    logistic: argv.logistic
    epochs: argv.epochs
    outfile: "#{argv.prefix}#{phase}"
    verbose: false

  coeffs_to_weights
    prefix: argv.prefix
    outfile: argv.weights
    verbose: false

  { winrate, avg } = match
    weights: argv.weights
    search: argv.search
    wld: argv.wld
    full: argv.full
    quiet: true
    openings: match.defaults.openings
    min: max

  score = winrate + avg * 0.0001
  process.stdout.write "score #{Math.round(100000*score)/100000}"
  if score > max
    process.stdout.write ' *\n'
  else
    process.stdout.write '\n'

  { score, coeffs }

optimize_match = (phase) ->
  prepare phase

  samples = minibatch.load_samples
    book: argv.book
    phase: phase
    logistic: argv.logistic
    verbose: true

  value =
    if argv.skip_cv
      parseFloat(fs.readFileSync("L2/#{phase}"))
    else
      minibatch
        search: true
        search_precision: 1.4
        search_min: argv.min * Math.sqrt(argv.match_range)
        search_max: argv.max / Math.sqrt(argv.match_range)
        samples: samples
        phase: phase
        logistic: argv.logistic
        epochs: argv.epochs

  ubound = value * argv.match_range
  lbound = value / argv.match_range
  step = (ubound / lbound) ** .25
  best = (lbound * ubound) ** .5
  { score, coeffs } = try_value(phase, best, -Infinity, samples)
  max = score
  best_coeffs = coeffs
  loop
    tmp = best * step
    { score, coeffs } = try_value(phase, tmp, max, samples)
    if score > max
      max = score
      best = tmp
      best_coeffs = coeffs
    else
      tmp = best / step
      { score, coeffs } = try_value(phase, tmp, max, samples)
      if score > max
        max = score
        best = tmp
        best_coeffs = coeffs
    break if step - 1 < argv.precision
    step **= .5
  console.log "Best value #{best}"
  fs.writeFileSync "L2/#{phase}", "#{best}\n"
  fs.writeFileSync "#{argv.prefix}#{phase}", JSON.stringify(best_coeffs)

do ->
  reload = watch_file('.reload-l2')
  until reload()
    for phase in [0...N_PHASES]
      continue if argv.phase? and phase != argv.phase
      console.log "Phase #{phase}"
      if phase <= 2
        optimize_cv phase
      else
        optimize_match phase
    break unless argv.loop
