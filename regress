#!/usr/bin/env coffee

require './rejection_handler'
{ readlines, gzwriter, round_value, shuffle } = require './util'
{ get_single_index_size } = require './pattern'

yargs = require 'yargs'
  .usage "Usage: #{process.argv[1]} [options] indexes coeffs"
  .options
    t:
      desc: 'threshold to terminate regression'
      alias: 'threshold'
      default: 1e-3
      type: 'number'
      requiresArg: true
    s:
      alias: 'split'
      desc: 'Split this ratio as train set, and rest as test set'
      default: null
      type: 'number'
      requiresArg: true
    d:
      alias: 'duration'
      desc: 'Duration of moving average of difference'
      default: 10
      type: 'number'
      requiresArg: true
    balance:
      desc: 'Thin out samples to get average closer to zero'
      type: 'boolean'
      default: false
    sgd:
      desc: 'Use SGD'
      type: 'boolean'
      default: true
    adagrad:
      desc: 'Use AdaGrad'
      type: 'boolean'
      default: true
    ridge:
      desc: 'L2 regularization parameter'
      type: 'number'
      default: 0
    h:
      alias: 'help'
  .version false
  .strict()

argv = yargs.argv

index_size = get_single_index_size()

each_index = (row, cb) ->
  for i in [1...row.length] by 2
    cb row[i], row[i+1]

predict = (coeffs, row) ->
  result = 0
  each_index row, (index, value) ->
    result += coeffs[index] * value
  result

verify = (rows, coeffs, upper) ->
  if upper?
    upper = upper * upper * rows.length if upper?
  else
    upper = Infinity
  sum_sq_err = 0
  for row from rows
    outcome = row[0]
    e = outcome - predict(coeffs, row)
    sum_sq_err += e*e
    if sum_sq_err > upper
      break
  Math.sqrt(sum_sq_err / rows.length)

make_gradient = (rows, coeffs) ->
  vector = (0 for i in [0...index_size] by 1)
  sum = 0
  for row from rows
    outcome = row[0]
    e = outcome - predict(coeffs, row)
    each_index row, (index, value) ->
      vector[index] += e * value
  vector

update_coeffs = (coeffs, vector, rate) ->
  coeffs[i] + vector[i] * rate for i in [0...index_size] by 1

sgd = (rows, coeffs, rate, max_loss) ->
  max_sum_e2 = (max_loss * max_loss) * rows.length
  new_coeffs = [coeffs...]
  sum_e2 = 0
  sum = 0
  for row from rows
    outcome = row[0]
    e = outcome - predict(new_coeffs, row)
    sum_e2 += e * e
    return null if sum_e2 > max_sum_e2
    each_index row, (index, value) ->
      new_coeffs[index] += rate * e * value
  new_coeffs

adagrad = (rows, coeffs, g2, rate, max_loss) ->
  max_sum_e2 = (max_loss * max_loss) * rows.length
  sum_e2 = 0
  sum = 0
  for row from rows
    outcome = row[0]
    e = outcome - predict(coeffs, row)
    sum_e2 += e * e
    return false if sum_e2 > max_sum_e2
    each_index row, (index, value) ->
      g = e * value
      if g
        if argv.ridge
          g -= argv.ridge * coeffs[index]
        g2[index] += g * g
        coeffs[index] += rate * g / Math.sqrt(g2[index])
  true

read_rows = (filename) ->
  console.log "loading #{filename}"
  rows = []
  await readlines filename, (line) ->
    rows.push JSON.parse line
  rows

binary_search = (samples, target) ->
  lbound = 0
  return lbound if target <= samples[lbound][0]
  ubound = samples.length - 1
  return ubound if target >= samples[ubound][0]
  while lbound < ubound
    mid = Math.round((lbound + ubound) / 2)
    value = samples[mid][0]
    return mid if value == target
    if value < target
      lbound = mid + 1
    else
      ubound = mid - 1
  mid

thin_out = (samples) ->
  balance = 0
  for sample in samples
    balance += sample[0]
  #console.log 'balance', balance
  orig_balance = balance
  samples.sort (a, b) -> a[0] - b[0]
  n_removed = 0
  while balance != 0
    #console.log 'balance', balance
    i = binary_search(samples, balance)
    value = samples[i][0]
    if value == 0
      #console.log 'abount to kill zero'
      break
    #console.log 'killing', value
    samples.splice i, 1
    n_removed++
    balance -= value
  console.log 'thinned out', n_removed, 'samples'
  {samples, n_removed}

split_rows = (rows, ratio) ->
  n_train = Math.round(ratio * rows.length)
  rows = shuffle rows
  train_set = rows.slice(0, n_train)
  test_set = rows.slice(n_train)
  {train_set, test_set}

average = (rows) ->
  sum = 0
  for row in rows
    sum += row[0]
  sum / rows.length

regress = (index_file) ->
  samples = await read_rows index_file
  n_samples = samples.length
  console.log 'loaded', n_samples, 'samples'
  raw_avg = average samples
  console.log 'samples avg', raw_avg

  if argv.balance
    {samples, n_removed} = thin_out(samples)
  if argv.split
    {train_set, test_set} = split_rows(samples, argv.split)
  else
    train_set = test_set = samples

  console.log "train set #{train_set.length} samples"
  console.log "test set #{test_set.length} samples"
  avg = average train_set
  console.log "train set avg #{avg}"
  coeffs = (0 for i in [0...index_size] by 1)
  dev = last_loss = verify train_set, coeffs
  console.log 'deviation', dev

  n = 0
  step = 1
  d_avg = 0
  rate = 100
  rate /= train_set.length unless argv.sgd
  finish = false
  min_loss = dev
  loop
    if argv.sgd
      train_set = shuffle train_set
      if argv.adagrad
        if step == 1
          loop
            g2 = (0 for i in [0...index_size] by 1)
            coeffs = (0 for i in [0...index_size] by 1)
            if adagrad(train_set, coeffs, g2, rate, dev)
              loss = verify test_set, coeffs, last_loss
              if loss < last_loss
                break
            rate *= 0.7
            if rate < 1e-3
              finish = true
              break
        else
          adagrad(train_set, coeffs, g2, rate, Infinity)
          loss = verify test_set, coeffs, last_loss
          if argv.split
            min_loss = loss if loss < min_loss
            break if loss > min_loss * (1 + argv.threshold)
      else
        loop
          max_loss = if step==1 then last_loss else Infinity
          new_coeffs = sgd(train_set, coeffs, rate, max_loss)
          if new_coeffs
            loss = verify test_set, new_coeffs, last_loss
            if loss < last_loss
              break
          train_set = shuffle train_set
          rate *= 0.7
          if rate < 1e-7
            finish = true
            break
        coeffs = new_coeffs
    else
      vector = make_gradient train_set, coeffs

      loop
        new_coeffs = update_coeffs coeffs, vector, rate
        loss = verify test_set, new_coeffs, last_loss
        break if loss < last_loss
        rate *= 0.7
        if rate*train_set.length < 1e-5
          finish = true
          break
      coeffs = new_coeffs
    break if finish

    d = Math.abs(last_loss - loss)
    if step <= argv.duration
      d_avg = (d_avg * (step - 1) + d) / step
    else
      d_avg = (d_avg * (argv.duration - 1) + d) / argv.duration

    display_rate = rate
    unless argv.adagrad
      display_rate *= train_set.length
    console.log 'step', step, 'loss', loss,
      'rate', round_value(display_rate),
      'd', d_avg
    break if step >= argv.duration and d_avg < argv.threshold

    step++

    last_loss = loss

    unless argv.sgd
      n++
      if n >= 30
        rate *= 10000
        n = 0

  r2 = 1 - last_loss**2 / dev**2
  console.log 'r2', r2

  {coeffs, r2, step, loss:last_loss, avg, n_samples, raw_avg, n_removed}

if argv._.length == 2
  [index_file, outfile] = argv._
else
  yargs.showHelp()
  process.exit 1

argv.sgd = true if argv.adagrad

do ->
  coeffs = await regress index_file
  gzwriter(outfile).end(JSON.stringify coeffs)
