#!/usr/bin/env coffee

require './rejection_handler'
{ gzwriter, round_value, shuffle } = require './util'
{ get_single_index_size, SCORE_MULT } = require './pattern'
Book = require './book'

argv = require 'yargs'
  .options
    p:
      alias: 'phase'
      desc: 'Phase (0-9)'
      type: 'number'
      requiresArg: true
      demandOption: true
    o:
      alias: 'outfile'
      desc: 'Output file'
      type: 'string'
      requiresArg: true
      demandOption: true
    b:
      alias: 'book'
      desc: 'Database file to read nodes from'
      type: 'string'
      requiresArg: true
      default: 'book.db'
    steps:
      desc: 'Number of iterations over samples'
      type: 'number'
      requiresArg: true
      default: 200
    t:
      desc: 'Threshold to terminate regression'
      alias: 'threshold'
      default: 1e-3
      type: 'number'
      requiresArg: true
    s:
      alias: 'split'
      desc: 'Split this ratio as train set, and rest as test set'
      default: null
      type: 'number'
      requiresArg: true
    balance:
      desc: 'Thin out samples to get average closer to zero'
      type: 'boolean'
      default: false
    sgd:
      desc: 'Use SGD'
      type: 'boolean'
      conflicts: 'rmsprop'
    adagrad:
      desc: 'Use AdaGrad'
      type: 'boolean'
      default: true
    rmsprop:
      desc: 'RMSProp parameter (e.g. 0.99)'
      type: 'number'
      default: undefined
      conflicts: 'sgd'
    rate:
      desc: 'Learning rate for AdaGrad/RMSProp'
      type: 'number'
      default: 0.08
    ridge:
      desc: 'L2 regularization parameter'
      type: 'number'
      default: 0
    logistic:
      desc: 'Logistic regression'
      type: 'boolean'
    d:
      alias: 'duration'
      desc: 'Depretcated. Ignored.'
    h:
      alias: 'help'
  .version false
  .strict()
  .argv

index_size = get_single_index_size()


clip = do ->
  MAX = 32767 / SCORE_MULT
  MIN = -32768 / SCORE_MULT
  (x) ->
    if x > MAX
      MAX
    else if x < MIN
      MIN
    else
      x

each_index = (row, cb) ->
  for i in [1...row.length] by 2
    cb row[i], row[i+1]

predict = (coeffs, row) ->
  result = 0
  each_index row, (index, value) ->
    result += coeffs[index] * value
  if argv.logistic
    1 / (1 + Math.exp(-result))
  else
    result

verify = (rows, coeffs, upper) ->
  if upper?
    upper = upper * upper * rows.length if upper?
  else
    upper = Infinity
  sum_sq_err = 0
  for row from rows
    outcome = row[0]
    e = outcome - predict(coeffs, row)
    sum_sq_err += e*e
    if sum_sq_err > upper
      break
  Math.sqrt(sum_sq_err / rows.length)

sgd = (rows, coeffs, rate, max_loss) ->
  max_sum_e2 = (max_loss * max_loss) * rows.length
  new_coeffs = [coeffs...]
  sum_e2 = 0
  sum = 0
  for row from rows
    outcome = row[0]
    e = predict(new_coeffs, row) - outcome
    sum_e2 += e * e
    return null if sum_e2 > max_sum_e2
    each_index row, (index, value) ->
      g = e * value
      if argv.ridge
        g += argv.ridge * coeffs[index]
      new_coeffs[index] = clip(new_coeffs[index] - rate * g)
  new_coeffs

adagrad = (rows, coeffs, g2, rate, max_loss) ->
  max_sum_e2 = (max_loss * max_loss) * rows.length
  sum_e2 = 0
  sum = 0
  for row from rows
    outcome = row[0]
    e = predict(coeffs, row) - outcome
    sum_e2 += e * e
    return false if sum_e2 > max_sum_e2
    each_index row, (index, value) ->
      g = e * value
      if g
        if argv.ridge
          g += argv.ridge * coeffs[index]
        if argv.rmsprop
          gg = g2[index] = g2[index] * argv.rmsprop + g * g * (1 - argv.rmsprop)
        else
          gg = g2[index] += g * g
        coeffs[index] = clip(coeffs[index] - rate * g / Math.sqrt(gg))
  true

binary_search = (samples, target) ->
  lbound = 0
  return lbound if target <= samples[lbound][0]
  ubound = samples.length - 1
  return ubound if target >= samples[ubound][0]
  while lbound < ubound
    mid = Math.round((lbound + ubound) / 2)
    value = samples[mid][0]
    return mid if value == target
    if value < target
      lbound = mid + 1
    else
      ubound = mid - 1
  mid

thin_out = (samples) ->
  balance = 0
  for sample in samples
    balance += sample[0]
  #console.log 'balance', balance
  orig_balance = balance
  samples.sort (a, b) -> a[0] - b[0]
  n_removed = 0
  while balance != 0
    #console.log 'balance', balance
    i = binary_search(samples, balance)
    value = samples[i][0]
    if value == 0
      #console.log 'abount to kill zero'
      break
    #console.log 'killing', value
    samples.splice i, 1
    n_removed++
    balance -= value
  console.log 'thinned out', n_removed, 'samples'
  {samples, n_removed}

split_rows = (rows, ratio) ->
  n_train = Math.round(ratio * rows.length)
  rows = shuffle rows
  train_set = rows.slice(0, n_train)
  test_set = rows.slice(n_train)
  {train_set, test_set}

average = (rows) ->
  sum = 0
  for row in rows
    sum += row[0]
  sum / rows.length

regress = (samples) ->
  n_samples = samples.length
  raw_avg = average samples
  console.log 'samples avg', raw_avg

  if argv.balance
    {samples, n_removed} = thin_out(samples)
  if argv.split
    {train_set, test_set} = split_rows(samples, argv.split)
  else
    train_set = test_set = samples

  console.log "train set #{train_set.length} samples"
  console.log "test set #{test_set.length} samples"
  avg = average train_set
  console.log "train set avg #{avg}"
  coeffs = (0 for i in [0...index_size] by 1)
  best_coeffs = [coeffs...]
  dev = last_loss = verify train_set, coeffs
  console.log 'deviation', dev

  rate = 100
  finish = false
  min_loss = dev
  for step in [1..argv.steps]
    if argv.adagrad
      train_set = shuffle train_set
      if step == 1
        last = false
        loop
          g2 = (0 for i in [0...index_size] by 1)
          coeffs = (0 for i in [0...index_size] by 1)
          if adagrad(train_set, coeffs, g2, rate, dev)
            loss = verify test_set, coeffs, last_loss
            if loss < last_loss
              if last
                break
              rate *= argv.rate / 0.7
              console.log 'rate', rate
              last = true
          rate *= 0.7
          if rate < 1e-4
            finish = true
            break
      else
        adagrad(train_set, coeffs, g2, rate, Infinity)
        loss = verify test_set, coeffs, last_loss
        if argv.split
          break if loss > min_loss * (1 + argv.threshold)
    else if argv.sgd
      train_set = shuffle train_set
      loop
        max_loss = if step==1 then last_loss else Infinity
        new_coeffs = sgd(train_set, coeffs, rate, max_loss)
        if new_coeffs
          loss = verify test_set, new_coeffs, last_loss
          if loss < last_loss
            break
        train_set = shuffle train_set
        rate *= 0.7
        if rate < 1e-10
          finish = true
          break
      console.log 'rate', rate
      coeffs = new_coeffs
    break if finish

    if loss < min_loss
      min_loss = loss
      best_coeffs = [coeffs...]

    d = last_loss - loss

    console.log 'step', step, 'loss', loss,
      'd', d,
      if loss == min_loss then '*' else ''

    last_loss = loss

  r2 = 1 - last_loss**2 / dev**2
  console.log 'r2', r2

  coeffs = best_coeffs
  loss = min_loss
  logistic = argv.logistic
  clip = 16
  {coeffs, r2, step, loss, avg, n_samples, raw_avg, n_removed, logistic, clip}

format_time = (msec) ->
  retval = ''
  s = msec % (60*1000)
  retval = "#{s/1000}s"
  m = Math.floor(msec / (60*1000))
  return retval unless m
  m = m % 60
  retval = "#{m}m" + retval
  h = Math.floor(m / 60)
  return retval unless h
  h = h % 24
  retval = "#{h}h" + retval
  d = Math.floor(h / 24)
  return retval unless d
  return "#{d}d" + retval

do ->
  argv.adagrad = false if argv.sgd
  argv.sgd = false if argv.adagrad

  book = new Book argv.book
  book.init()

  t0 = Date.now()

  process.stdout.write "Loading samples of phase #{argv.phase}: "
  t = Date.now()
  samples = []
  for sample from book.iterate_indexes(argv.phase)
    if argv.logistic
      sample[0] = if sample[0] > 0 then 1 else 0
    samples.push sample
  t = Date.now() - t
  console.log "loaded #{samples.length} samples in #{t/1000} seconds"

  coeffs = regress samples

  process.stdout.write "Writing coeffs to #{argv.outfile}: "
  gzwriter(argv.outfile).end(JSON.stringify coeffs)
  console.log 'done'

  t0 = Date.now() - t0
  console.log "Elapsed time #{format_time(t0)}"
